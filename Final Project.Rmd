---
title: "Final Project(NBA)"
author: "Shuheng Zhao & Ziwei Zeng"
date: "5/01/2017"
output:
  word_document: default
  html_document: default
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,warning=F,message=F)
```

#NBA is the National Basketball Association. It is the major men's professional basketball league in North America, and is widely considered to be the premier men's professional basketball league in the world. The NBA consists of 30 teams, 29 in the United States and 1 in Canada. We know that small ball lineups are now popular in the league.People always assume that having a small ball lineup will give the team a better socring ability than having a tradition lineup. As we know,  small ball lineups are good at assists since every one on the lineup has the ablity of passing the ball. Also, more passing usually leads to more turnovers. Last but not least, small ball lineups are good at attacting the basket and drawing fouls, therefore, free throws are usually going to be increased when we have a small ball lineup. In addition, we know that small ball lineups are not good defensive lineups. Having a small ball lineup will let the team have less blocks and steals. Therefore, we would like to analysis how a team's offense can be affected by the "small ball lineup" factors. We would like to find the relationships between the points socred and these factors to check whether a small ball lineup does actually give a team a better scoring ability. We will want to derive an equation.

The report of the work divided into two parts Exploring descriptive analysis and statistical modeling.


__Part I EDA__

Before we start perform exploring descriptive analysis, we first give overviews of the data:

```{r}
library(readr)
library(dplyr)
library(ggplot2)
library(knitr)
data = read_csv("D:/DA101file/Final/1516NBAcleaned.csv")
data = data.frame(data)
#glimpse
glimpse(data)
```

Then we summarize the performances of small ball lineup factors on team level, the table is given as follows:

```{r}
#Group_by, summarise, sub
data$team<-sub("^","15",data$team)
table1<- data%>%  group_by(team)%>%   summarise(points=sum(points,na.rm=TRUE),OR=sum(type=="rebound offensive"))
table1<-mutate(table1,PTSPG=points/82, ORPG=OR/82)
#Remove NAs
table2<- data%>%
  group_by(team)%>%
  summarise(Steals = sum(!is.na(steal)), Blocks = sum(!is.na(block)), Assist = sum(!is.na(assist)), Turnovers=sum(event_type=="turnover"),TwoMade=length(which(points==2)),ThreeMade=length(which(points==3)),TotalFG=sum(event_type=="shot")+sum(event_type=="miss"),EFGP=(TwoMade+1.5*ThreeMade)/TotalFG,FreeThrow=sum(event_type=="free throw"),FTMade=length(which(result=="made"))-length(which(event_type=="shot")))
#left join
table3<-left_join(table2,table1,by=c("team"))
#Filter
table3 <- table3%>%   filter(!is.na(team))
#mutate
table3 <-mutate(table3,PTSPG=points/82)

#check first 6 and last 6 rows
tb = rbind(table3[1:6, ], table3[(nrow(table3) - 5):nrow(table3),])
kable(tb)
```

It can be found that each team has different performances in the various ascepts. And we check the types frequency and show the top 10 most types:

```{r}
#table
tb = table(data$type)
tb10 = sort(tb, decreasing = T)[1:10]
tb10
```

Now we check the relationships between ORPG and PTSPG use Bivariate Regression:

```{r}
#summary
reg<-lm(PTSPG~ORPG,table3)
summary(reg)
```

The 95% confindence interval for the estimated slope is:

```{r}
#Confidence intervals
confint(reg)
```

It can be found the predictor ORPG is significant with p value less than 0.05, and then we check the relationships between ORPG, EFGP and PTSPG use Multivariate regression:

```{r}
reg2<-lm(PTSPG~ORPG+EFGP,table3)
summary(reg2)
```

The output also show the both of the predictors are significant, then we check the residuals of the model:

```{r}
res = table3$PTSPG  - predict(reg2)
table3<-mutate(table3,resid2=res)
table3 <-rename(table3, residual = resid2)
#Histogram, freqpoly
table3%>%
  ggplot(aes(residual))+
  geom_histogram(colour="blue",fill="red",bins=30) +  geom_freqpoly()


#scatter
table3%>%
  ggplot(aes(ORPG,residual))+
  geom_point()+geom_smooth(method="lm")+
  xlab("offisive rebounds per game")
```

Shapiro-wilk test to test the noramlity of the residuals:

```{r}
shapiro.test(res)
```

The p value is  0.7086 > 0.05 which means the normality is true for the regression.


Next. We seperate the teams by blocks and assists. We would like to find the points socred by teams that have blocks above and below the average, and assists above and below the average.

```{r}
#Bar 
table3 = data.frame(table3)
table3 <- mutate(table3, HighAssist = if_else(Assist > mean(Assist), "HighAssist", "LowAssit"), Highblocks = if_else(Blocks > mean(Blocks), "HighBlocks", "LowBlocks"))
ggplot(table3, aes(Highblocks,points)) + geom_bar(stat = "identity") + facet_wrap(~HighAssist) + xlab("Blocks")
```

The bar plots show there are difference between the high block teams and high assist teams in points. And we check the average points between the two groups of high blocks and low blocks teams:

```{r}
ggplot(table3, aes(Highblocks,points)) + geom_boxplot()+xlab("Blocks")
```

So low block teams have an average higher points which means they are more focus on getting points.


Finally, we perform some formal statistical tests including Independent samples T-test, One-sample T-test and  Correlation test:

First, we check if there is correlation between Two Made shot and Three MAde ones, the result is:

```{r}
#select
table4 = select(table3, c(TwoMade, ThreeMade))
with(table4, cor.test(TwoMade, ThreeMade))
```

The p value is much lower than 0.05, so it means we should reject the independent of the two variables.

For One-sample T-test, we want to t test if the average shot distance is less than 12.

```{r}
 with(data, t.test(shot_distance, mu = 12, alternative = "greater"))
```

So the p value is less than 0.05, we should reject H0 and conclude the average shot distance is greater than 12.


For independent samples T-test, we want to test if the away score and home score are equal.

```{r}
with(data, t.test(away_score, home_score))
```


So the p value is less than 0.05, we should reject H0 and conclude the two scores are not equal.


__Part II Modeling__


In this section, based on the exploring results from Part I, we are aim to find relationships among the variables via linear regression model, in our case, we want to find the relationships among the points with steals, blocks, assist , Turnovers and FreeThrow, we would like to regress points on the 4 factors and based on the model, we can not only interpret the predictors but also can predict the response variable in the future when given the predictors.

First, we show an overall of relationships among the variables using scatter plot matrix among the response points and the 5 predictors:

```{r,echo=F}
pairs(table3[ ,c(2,3,4,5,6,7,12)], pch = 20, col = "red")
```
This plot shows all the relationship among the variables. By using this plot, we don't have to plot multiple times to observe the relationships. From this plot, we can't observe that there are any direct relationships between any specific variables besides steals and turnovers.

Therefore, we need to build a model which decribe the relationshiop between points socred and all the factors above, the model is:

$$Points = \beta_0 + \beta_1Steals + \beta_2Blocks + \beta_3Assist + \beta_4Turnovers + \beta_5FreeThrow$$

And the result of the model is:

```{r,echo=F}
mod = lm(points ~ Steals + Blocks + Assist + Turnovers +  FreeThrow,  data = table3)
summary(mod)
```

The p-value is small (2.674e-05) so the null hypothesis that the true slope is 0 is accepted. Thus, the variables combination has strong relationship with points made, and so these variables are significant. From the analysis, we can get the coefficients of the linear model. Therefore, we can have an equation shows the relationship between the factors and the points socred. We also find that the R squred value is 0.6, which is pretty large. Therefore, this linear model fits pretty well.

So the model estimated is:

$$Points = 5012.4582  -1.2889Steals-1.0504Blocks + 1.3791Assist+   0.7083Turnovers + 0.7001FreeThrow$$

Now we perform model diagnostic plots to check the assumptions of the above model, the plots are shown as below:

"
```{r,echo=F}
par(mfrow = c(1,2))
plot(mod, 1:2, pch = 20)
```


These two plots test the normality of the linear model. The left residuals plot shows that the spread of points do not change across the x-axis which means the constant variance is satisfied and there is no special curve which means linearity is true and the right normal qq plot shows the points fit the straight line quite well which means the normality assumption is true, so our model is valid.

Therefore, we can conclude that the relationship between the points socred and the "small ball lineup" factors is the following equation: $$Points = 5012.4582  -1.2889Steals-1.0504Blocks + 1.3791Assist+   0.7083Turnovers + 0.7001FreeThrow$$
From this equation, we can see that the coefficient before steals and blocks are negative numbers. Therefore, having more steals and blocks leads to scoring less points. Since having a traditional lineup will give the team a better defense, in other words, more steals and blocks. We can interpret this result as having a tradition lineup leads to scoring less points. Then, the coefficients before Assists, Turnovers and Freethrows are all positive. Therefore, having more assists, turnovers and freethrows leads to scoring more points. And since small ball lineups bring more of those stats than the traditional lineups, having a small ball lineup will let the team to score more points. 

#In conclusion, having a small ball lineup does give a team a better scoring ability than having a traditional lineup.























